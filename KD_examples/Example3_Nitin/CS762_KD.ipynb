{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://8080-cs-8fccdb3f-9107-4313-8c25-4ebf00823ff4.cs-us-central1-pits.cloudshell.dev/"
    },
    "id": "gDDz3zyMPWet",
    "outputId": "2d97473e-a723-4a24-dc7b-f96eebd878f0"
   },
   "outputs": [],
   "source": [
    "!python main.py --model_dir experiments/base_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BIGGER = 160\n",
    "RESIZE = 128\n",
    "CENTRAL_FRAC = 0.875\n",
    "\n",
    "SCHEDULE_LENGTH = 500\n",
    "SCHEDULE_LENGTH = (SCHEDULE_LENGTH * 512 / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation motivated from here:\n",
    "# https://github.com/google-research/big_transfer/blob/master/colabs/big_transfer_tf2.ipynb.\n",
    "def augment(image):\n",
    "    # Resize to a bigger shape, randomly horizontally flip it,\n",
    "    # and then take the crops. \n",
    "    image = tf.image.resize(image, (BIGGER, BIGGER))\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_crop(image, [RESIZE, RESIZE, 3])\n",
    "    return image\n",
    "\n",
    "    \n",
    "# Function to read the TFRecords, segregate the images and labels.\n",
    "def read_tfrecord(example, train):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n",
    "    \n",
    "    if train:\n",
    "        image = augment(image)\n",
    "    else:\n",
    "        image = tf.image.central_crop(image, central_fraction=CENTRAL_FRAC)\n",
    "        image = tf.image.resize(image, (RESIZE, RESIZE))\n",
    "        \n",
    "    image = tf.reshape(image, (RESIZE, RESIZE, 3))\n",
    "    image = tf.cast(image, tf.float32) / 255.0  \n",
    "    class_label = tf.cast(example[\"class\"], tf.int32)\n",
    "    return (image, class_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss\n",
    "\n",
    "lr = (1e-5 * BATCH_SIZE / 512)\n",
    "\n",
    "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[200, 300, 400], \n",
    "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://8080-cs-8fccdb3f-9107-4313-8c25-4ebf00823ff4.cs-us-central1-pits.cloudshell.dev/",
     "height": 265
    },
    "id": "kpzuU3cey_uM",
    "outputId": "25fa79e1-2195-4ea5-db37-dd11dfc18bca"
   },
   "outputs": [],
   "source": [
    "# # Extract data from log files and plot\n",
    "\n",
    "filename = '/content/drive/MyDrive/CS762/experiments/base_resnet18/train.log'\n",
    "\n",
    "train_acc = []\n",
    "loss = []\n",
    "eval_acc = []\n",
    "\n",
    "with open(filename) as file:\n",
    "  for line in file:\n",
    "    l = line.rstrip()\n",
    "    if 'Train metrics' in l:\n",
    "      train_acc.append(float(l[-19:-14]))\n",
    "      loss.append(float(l[-5:]))\n",
    "    if 'Eval metrics' in l:\n",
    "      eval_acc.append(float(l[-19:-14]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_acc)\n",
    "plt.plot(eval_acc)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNf4SHC9XjAR"
   },
   "outputs": [],
   "source": [
    "#drive.flush_and_unmount()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('3.9.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc914d51665d695d2987fe5f71ef05697c600e9a920efbecbf3af056d7157c87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
